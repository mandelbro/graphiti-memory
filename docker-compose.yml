services:
  # Optional: Ollama service for LLM operations
  # Uncomment and use this if you want to run Ollama in a container
  # ollama:
  #   image: ollama/ollama:latest
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:11434/v1/models"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 60s

  neo4j:
    image: neo4j:5.26.0
    ports:
      - "7474:7474" # HTTP
      - "7687:7687" # Bolt
    environment:
      - NEO4J_AUTH=${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-demodemo}
      - NEO4J_server_memory_heap_initial__size=512m
      - NEO4J_server_memory_heap_max__size=1G
      - NEO4J_server_memory_pagecache_size=512m
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    healthcheck:
      test: ["CMD", "wget", "-O", "/dev/null", "http://localhost:7474"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  graphiti-mcp:
    build:
      context: .
      dockerfile: ${DOCKERFILE:-Dockerfile}
      secrets:
        # Pass SSL certificate to build process if SSL_CERT_FILE is set
        - ssl_cert
    develop:
      watch:
        - path: ./src
          action: sync
          target: /app/src
        - path: ./pyproject.toml
          action: sync
          target: /app/pyproject.toml
        - path: ./uv.lock
          action: sync
          target: /app/uv.lock
        - path: ./Dockerfile
          action: rebuild
    env_file:
      - path: .env
        required: true
    depends_on:
      neo4j:
        condition: service_healthy
    environment:
      # Neo4j Configuration
      - NEO4J_URI=${NEO4J_URI:-bolt://neo4j:7687}
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-demodemo}
      # API Key (passed from .env, works for both OpenAI and Bedrock)
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      # Path configuration
      - PATH=/root/.local/bin:${PATH}
      - PYTHONPATH=/app
      # Server configuration
      - SEMAPHORE_LIMIT=${SEMAPHORE_LIMIT:-10}
      - MCP_SERVER_PORT=${MCP_SERVER_PORT:-8020}
      - MCP_INTERNAL_PORT=${MCP_INTERNAL_PORT:-$((MCP_SERVER_PORT + 1))}
      # OAuth Configuration
      - OAUTH_CLIENT_ID=${OAUTH_CLIENT_ID:-graphiti-mcp}
      - OAUTH_CLIENT_SECRET=${OAUTH_CLIENT_SECRET:-graphiti-secret-key-change-this-in-production}
      - OAUTH_ISSUER=${OAUTH_ISSUER:-http://localhost:8020}
      - OAUTH_AUDIENCE=${OAUTH_AUDIENCE:-graphiti-mcp}
      # Analytics Configuration (optional - disable PostHog telemetry)
      # Note: graphiti-core expects GRAPHITI_TELEMETRY_ENABLED (false to disable)
      - GRAPHITI_TELEMETRY_ENABLED=${GRAPHITI_TELEMETRY_ENABLED:-true}
      # SSL Certificate paths for Docker container (optional)
      # If custom CA cert was installed during build, point to system trust store
      # Otherwise, these will be empty and system defaults will be used
      - SSL_CERT_FILE=${SSL_CERT_FILE_DOCKER:-/etc/ssl/certs/ca-certificates.crt}
      - REQUESTS_CA_BUNDLE=${REQUESTS_CA_BUNDLE_DOCKER:-/etc/ssl/certs/ca-certificates.crt}
      - CURL_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt
    # SSL certificate volume mount (enabled for custom CA certificates)
    volumes:
      - ${SSL_CERT_DIR}:/app/.certs:ro
    ports:
      - "${MCP_SERVER_PORT:-8020}:8020" # Expose the OAuth wrapper
    command: ["sh", "-c", ".venv/bin/python src/graphiti_mcp_server.py --transport sse --port $MCP_INTERNAL_PORT & .venv/bin/python src/oauth_wrapper.py"]

volumes:
  neo4j_data:
  neo4j_logs:
  # ollama_data:  # Uncomment if using Ollama service

secrets:
  # SSL certificate for build process
  # Set SSL_CERT_BUILD_PATH in .env to the full path of your certificate file
  # Example: SSL_CERT_BUILD_PATH=/Users/yourname/.certs/ca-bundle.pem
  # Defaults to /dev/null so build still works without SSL certs
  ssl_cert:
    file: ${SSL_CERT_BUILD_PATH:-/dev/null}
